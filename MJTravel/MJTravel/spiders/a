# -*- coding:utf-8 -*-

from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import Selector
from CSDNBlogCrawlSpider.items import CsdnblogcrawlspiderItem

class CSDNBlogCrawlSpider(CrawlSpider):
  """继承自CrawlSpider，实现自动爬取的爬虫。"""
  
  name = "CSDNBlogCrawlSpider"
  #设置下载延时
  download_delay = 2
  allowed_domains = ['blog.csdn.net']
  start_urls = ['http://blog.csdn.net/u012150179/article/details/11749017']

  rules = [
   Rule(SgmlLinkExtractor(allow=('/u012150179/article/details'),
        restrict_xpaths=('//li[@class="next_article"]')),
        callback='parse_item',
        follow=True)
  ]

  def parse_item(self, response):
   item = CsdnblogcrawlspiderItem()
   sel = Selector(response)
   blog_url = str(response.url)
   blog_name = sel.xpath('//div[@id="article_details"]/div/h1/span/a/text()').extract()
   item['blog_name'] = [n.encode('utf-8') for n in blog_name]
   item['blog_url'] = blog_url.encode('utf-8')
   yield item  
           'http://you.ctrip.com/travels/haikou37.html',
            'http://you.ctrip.com/travels/sanya61.html',
